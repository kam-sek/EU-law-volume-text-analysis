{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the directory if it doesn't exist\n",
    "output_dir = '../Data/Regulations'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# List to store CELEX numbers for which the document does not exist\n",
    "not_found_celex_numbers = []\n",
    "\n",
    "# Function to download the HTML content for each CELEX number\n",
    "def download_celex_html(celex_number, iteration):\n",
    "    file_path_html = os.path.join(output_dir, f'{celex_number}.html')\n",
    "    url_html = f'https://eur-lex.europa.eu/legal-content/EN/TXT/HTML/?uri=CELEX:{celex_number}'\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url_html)\n",
    "        response.raise_for_status()  # Check if the request was successful\n",
    "        html_content = response.text\n",
    "\n",
    "        # Check if the \"document does not exist\" message is present in the HTML version\n",
    "        if 'The requested document does not exist.' in html_content:\n",
    "            print(f\"[{iteration}/{total_celex_codes}] {celex_number} document does not exist in HTML.\")\n",
    "            not_found_celex_numbers.append(celex_number)\n",
    "            return False\n",
    "\n",
    "        # Save the HTML content if the document exists\n",
    "        with open(file_path_html, 'w', encoding='utf-8') as file:\n",
    "            file.write(html_content)\n",
    "        print(f\"[{iteration}/{total_celex_codes}] {celex_number} HTML document downloaded and saved.\")\n",
    "        return True\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[{iteration}/{total_celex_codes}] Failed to download HTML for {celex_number}. Error: {e}\")\n",
    "        not_found_celex_numbers.append(celex_number)\n",
    "        return False\n",
    "\n",
    "def download_celex_pdf(celex_number, iteration):\n",
    "    pdf_found = False  # Flag to check if any PDF file was found\n",
    "    url_pdf = f'https://eur-lex.europa.eu/legal-content/EN/TXT/PDF/?uri=CELEX:{celex_number}'\n",
    "\n",
    "    try:\n",
    "        response_pdf = requests.get(url_pdf, stream=True)\n",
    "        response_pdf.raise_for_status()\n",
    "\n",
    "        # Check the content type of the response to determine if it's a direct file download\n",
    "        content_type = response_pdf.headers.get('Content-Type', '')\n",
    "\n",
    "        # If the content is a PDF file (based on the MIME type), save it directly\n",
    "        if 'application/pdf' in content_type:\n",
    "            file_path = os.path.join(output_dir, f'{celex_number}.pdf')\n",
    "            download_and_save_file(response_pdf, file_path)\n",
    "            print(f\"[{iteration}/{total_celex_codes}] {celex_number} PDF file downloaded directly and saved.\")\n",
    "            pdf_found = True\n",
    "\n",
    "        else:\n",
    "            # Otherwise, treat the response as HTML and parse for PDF links\n",
    "            soup = BeautifulSoup(response_pdf.text, 'html.parser')\n",
    "            act_link = soup.find('a', href=lambda href: href and 'DOC_1' in href and 'format=PDF' in href)\n",
    "            annex_link = soup.find('a', href=lambda href: href and 'DOC_2' in href and 'format=PDF' in href)\n",
    "\n",
    "            if act_link:\n",
    "                # Construct the full URL for the main act\n",
    "                act_url = f\"https://eur-lex.europa.eu{act_link['href'].replace('./../../../../', '/')}\"\n",
    "                download_and_save_file_from_url(act_url, os.path.join(output_dir, f'{celex_number}.pdf'))\n",
    "                print(f\"[{iteration}/{total_celex_codes}] {celex_number} main act (PDF) downloaded and saved.\")\n",
    "                pdf_found = True\n",
    "\n",
    "            if annex_link:\n",
    "                # Construct the full URL for the annex\n",
    "                annex_url = f\"https://eur-lex.europa.eu{annex_link['href'].replace('./../../../../', '/')}\"\n",
    "                download_and_save_file_from_url(annex_url, os.path.join(output_dir, f'{celex_number}_Annex.pdf'))\n",
    "                print(f\"[{iteration}/{total_celex_codes}] {celex_number} annex (PDF) downloaded and saved.\")\n",
    "                pdf_found = True\n",
    "\n",
    "        return pdf_found\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[{iteration}/{total_celex_codes}] Failed to retrieve PDF page for {celex_number}. Error: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Function to download DOC or DOCX content for each CELEX number\n",
    "def download_celex_doc(celex_number, iteration):\n",
    "    doc_found = False  # Flag to check if any DOC file was found\n",
    "    url_doc = f'https://eur-lex.europa.eu/legal-content/EN/TXT/DOC/?uri=CELEX:{celex_number}'\n",
    "\n",
    "    try:\n",
    "        response_doc = requests.get(url_doc, stream=True)\n",
    "        response_doc.raise_for_status()\n",
    "\n",
    "        # Check the content type of the response to determine if it's a direct file download\n",
    "        content_type = response_doc.headers.get('Content-Type', '')\n",
    "\n",
    "        # If the content is a DOC file (based on the MIME type), save it directly\n",
    "        if 'application/msword' in content_type or 'application/vnd.openxmlformats-officedocument' in content_type:\n",
    "            file_extension = get_file_extension(content_type)\n",
    "            file_path = os.path.join(output_dir, f'{celex_number}{file_extension}')\n",
    "            download_and_save_file(response_doc, file_path)\n",
    "            print(f\"[{iteration}/{total_celex_codes}] {celex_number} DOC file downloaded directly and saved.\")\n",
    "            return True\n",
    "\n",
    "        else:\n",
    "            # Otherwise, treat the response as HTML and parse for DOC_1 and DOC_2 links\n",
    "            soup = BeautifulSoup(response_doc.text, 'html.parser')\n",
    "            act_link = soup.find('a', href=lambda href: href and 'DOC_1' in href)\n",
    "            annex_link = soup.find('a', href=lambda href: href and 'DOC_2' in href)\n",
    "\n",
    "            if act_link:\n",
    "                # Download and save the main act\n",
    "                act_url = f\"https://eur-lex.europa.eu{act_link['href']}\"\n",
    "                download_and_save_file_from_url(act_url, os.path.join(output_dir, f'{celex_number}.doc'))\n",
    "                print(f\"[{iteration}/{total_celex_codes}] {celex_number} main act (DOC) downloaded and saved.\")\n",
    "                doc_found = True\n",
    "\n",
    "            if annex_link:\n",
    "                # Download and save the annex\n",
    "                annex_url = f\"https://eur-lex.europa.eu{annex_link['href']}\"\n",
    "                download_and_save_file_from_url(annex_url, os.path.join(output_dir, f'{celex_number}_Annex.doc'))\n",
    "                print(f\"[{iteration}/{total_celex_codes}] {celex_number} annex (DOC) downloaded and saved.\")\n",
    "                doc_found = True\n",
    "\n",
    "        return doc_found\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"[{iteration}/{total_celex_codes}] Failed to retrieve DOC page for {celex_number}. Error: {e}\")\n",
    "        return False\n",
    "\n",
    "# Helper function to download and save a file from a direct response\n",
    "def download_and_save_file(response, file_path):\n",
    "    try:\n",
    "        with open(file_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                file.write(chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to save file: {file_path}. Error: {e}\")\n",
    "\n",
    "# Helper function to download and save a file from a URL\n",
    "def download_and_save_file_from_url(url, file_path):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Failed to download file from {url}. Error: {e}\")\n",
    "\n",
    "# Helper function to get the file extension from the Content-Type header\n",
    "def get_file_extension(content_type):\n",
    "    if 'application/msword' in content_type:\n",
    "        return '.doc'\n",
    "    elif 'application/vnd.openxmlformats-officedocument.wordprocessingml.document' in content_type:\n",
    "        return '.docx'\n",
    "    return '.doc'  # Default to .doc if unsure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a webscrapped dataset\n",
    "proposals_load = pd.read_csv('../Data/proposals_processed.csv')\n",
    "\n",
    "#Get unique CELEX numbers\n",
    "unique_celex_numbers = proposals_load['CELEX'].unique()\n",
    "\n",
    "#Show total number of unique CELEX codes\n",
    "total_celex_codes = len(unique_celex_numbers)\n",
    "print(f\"Total number of unique CELEX codes: {total_celex_codes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted CELEX numbers from PDF files: ['52000PC0751', '52001PC0695', '52001PC0775', '52002PC0336', '52004PC0486(01)', '52004PC0486(02)', '52004PC0599', '52004PC0629', '52004PC0708', '52004PC0718', '52005PC0343', '52005PC0447', '52005PC0505', '52005PC0566', '52005PC0650', '52006PC0286', '52006PC0543', '52009PC0546', '52010PC0510', '52011PC0349', '52012PC0064', '52013PC0265', '52015PC0174', '52015PC0180', '52015PC0220', '52017PC0545', '52021PC0556', '52022PC0151', '52022PC0174']\n"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# # Function to extract CELEX numbers from PDF files in the Regulations directory\n",
    "# def extract_celex_numbers_from_pdfs(directory):\n",
    "#     # List to store CELEX numbers\n",
    "#     celex_numbers = []\n",
    "\n",
    "#     # Loop through all the files in the directory\n",
    "#     for filename in os.listdir(directory):\n",
    "#         # Check if the file has a .pdf extension\n",
    "#         if filename.endswith('.pdf'):\n",
    "#             # Extract the CELEX number from the filename (assuming the filename format is 'CELEXNUMBER.pdf')\n",
    "#             celex_number = filename.replace('.pdf', '')\n",
    "#             celex_numbers.append(celex_number)\n",
    "\n",
    "#     return celex_numbers\n",
    "\n",
    "# # Call the function and pass the Regulations directory\n",
    "# pdf_celex_numbers = extract_celex_numbers_from_pdfs(output_dir)\n",
    "\n",
    "# # Print the extracted CELEX numbers\n",
    "# print(f\"Extracted CELEX numbers from PDF files: {pdf_celex_numbers}\")\n",
    "# total_celex_codes = len(pdf_celex_numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/29] 52000PC0751 document does not exist in HTML.\n",
      "[1/29] 52000PC0751 PDF file downloaded directly and saved.\n",
      "[2/29] 52001PC0695 document does not exist in HTML.\n",
      "[2/29] 52001PC0695 PDF file downloaded directly and saved.\n",
      "[3/29] 52001PC0775 document does not exist in HTML.\n",
      "[3/29] 52001PC0775 PDF file downloaded directly and saved.\n",
      "[4/29] 52002PC0336 document does not exist in HTML.\n",
      "[4/29] 52002PC0336 PDF file downloaded directly and saved.\n",
      "[5/29] 52004PC0486(01) document does not exist in HTML.\n",
      "[5/29] 52004PC0486(01) PDF file downloaded directly and saved.\n",
      "[6/29] 52004PC0486(02) document does not exist in HTML.\n",
      "[6/29] 52004PC0486(02) PDF file downloaded directly and saved.\n",
      "[7/29] 52004PC0599 document does not exist in HTML.\n",
      "[7/29] 52004PC0599 PDF file downloaded directly and saved.\n",
      "[8/29] 52004PC0629 document does not exist in HTML.\n",
      "[8/29] 52004PC0629 PDF file downloaded directly and saved.\n",
      "[9/29] 52004PC0708 document does not exist in HTML.\n",
      "[9/29] 52004PC0708 PDF file downloaded directly and saved.\n",
      "[10/29] 52004PC0718 document does not exist in HTML.\n",
      "[10/29] 52004PC0718 PDF file downloaded directly and saved.\n",
      "[11/29] 52005PC0343 document does not exist in HTML.\n",
      "[11/29] 52005PC0343 PDF file downloaded directly and saved.\n",
      "[12/29] 52005PC0447 document does not exist in HTML.\n",
      "[12/29] 52005PC0447 PDF file downloaded directly and saved.\n",
      "[13/29] 52005PC0505 document does not exist in HTML.\n",
      "[13/29] 52005PC0505 PDF file downloaded directly and saved.\n",
      "[14/29] 52005PC0566 document does not exist in HTML.\n",
      "[14/29] 52005PC0566 PDF file downloaded directly and saved.\n",
      "[15/29] 52005PC0650 document does not exist in HTML.\n",
      "[15/29] 52005PC0650 PDF file downloaded directly and saved.\n",
      "[16/29] 52006PC0286 document does not exist in HTML.\n",
      "[16/29] 52006PC0286 PDF file downloaded directly and saved.\n",
      "[17/29] 52006PC0543 document does not exist in HTML.\n",
      "[17/29] 52006PC0543 PDF file downloaded directly and saved.\n",
      "[18/29] 52009PC0546 document does not exist in HTML.\n",
      "[18/29] 52009PC0546 PDF file downloaded directly and saved.\n",
      "[19/29] 52010PC0510 document does not exist in HTML.\n",
      "[19/29] 52010PC0510 PDF file downloaded directly and saved.\n",
      "[20/29] 52011PC0349 document does not exist in HTML.\n",
      "[20/29] 52011PC0349 PDF file downloaded directly and saved.\n",
      "[21/29] 52012PC0064 document does not exist in HTML.\n",
      "[21/29] 52012PC0064 PDF file downloaded directly and saved.\n",
      "[22/29] 52013PC0265 document does not exist in HTML.\n",
      "[22/29] 52013PC0265 PDF file downloaded directly and saved.\n",
      "[23/29] 52015PC0174 document does not exist in HTML.\n",
      "[23/29] 52015PC0174 PDF file downloaded directly and saved.\n",
      "[24/29] 52015PC0180 document does not exist in HTML.\n",
      "[24/29] 52015PC0180 main act (PDF) downloaded and saved.\n",
      "[24/29] 52015PC0180 annex (PDF) downloaded and saved.\n",
      "[25/29] 52015PC0220 document does not exist in HTML.\n",
      "[25/29] 52015PC0220 main act (PDF) downloaded and saved.\n",
      "[25/29] 52015PC0220 annex (PDF) downloaded and saved.\n",
      "[26/29] 52017PC0545 document does not exist in HTML.\n",
      "[26/29] 52017PC0545 main act (PDF) downloaded and saved.\n",
      "[26/29] 52017PC0545 annex (PDF) downloaded and saved.\n",
      "[27/29] 52021PC0556 document does not exist in HTML.\n",
      "[27/29] 52021PC0556 main act (PDF) downloaded and saved.\n",
      "[27/29] 52021PC0556 annex (PDF) downloaded and saved.\n",
      "[28/29] 52022PC0151 document does not exist in HTML.\n",
      "[28/29] 52022PC0151 main act (PDF) downloaded and saved.\n",
      "[28/29] 52022PC0151 annex (PDF) downloaded and saved.\n",
      "[29/29] 52022PC0174 document does not exist in HTML.\n",
      "[29/29] 52022PC0174 main act (PDF) downloaded and saved.\n",
      "[29/29] 52022PC0174 annex (PDF) downloaded and saved.\n",
      "\n",
      "Saved the list of CELEX numbers for which the document does not exist to 'not_found_celex_numbers.csv'.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Iterate over the provided CELEX numbers\n",
    "for i, celex in enumerate(unique_celex_numbers, start=1):\n",
    "    # First try downloading the HTML\n",
    "    if not download_celex_html(celex, i):\n",
    "        # If HTML doesn't exist, try downloading the PDF\n",
    "        if not download_celex_pdf(celex, i):\n",
    "            # If PDF doesn't exist, try downloading the DOC\n",
    "            download_celex_doc(celex, i)\n",
    "\n",
    "    sleep(1)  # To avoid overwhelming the server, add a delay between requests.\n",
    "\n",
    "# Save the CELEX numbers for which the document does not exist as a DataFrame\n",
    "if not_found_celex_numbers:\n",
    "    not_found_df = pd.DataFrame(not_found_celex_numbers, columns=['CELEX'])\n",
    "    not_found_df.to_csv('../Data/not_found_celex_numbers.csv', index=False)\n",
    "    print(f\"\\nSaved the list of CELEX numbers for which the document does not exist to 'not_found_celex_numbers.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
